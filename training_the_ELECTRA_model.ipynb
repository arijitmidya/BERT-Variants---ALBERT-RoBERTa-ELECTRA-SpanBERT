{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT variant : ELECTRA\n",
    "\n",
    "Efficiently Learning an Encoder that Classifies Token Replacements Accurately (ELECTRA) is another interesting variant of BERT. We pre-train BERT \n",
    "using the MLM and NSP tasks. We know that in the MLM task, we randomly mask 15% of the tokens and train BERT to predict the masked token. Instead of\n",
    "using the MLM task as a pre-training objective, ELECTRA is pre-trained using a task called replaced token detection.\n",
    "\n",
    "The replaced token detection task : \n",
    "The replaced token detection task is very similar to MLM, but instead of masking a token with the [MASK] token, we replace a token with a different \n",
    "token and train the model to classify whether the given tokens are actual or replaced tokens.\n",
    "\n",
    "Why choose ELECTRA over BERT : \n",
    "One of the advantages of ELECTRA compared to BERT is that in BERT, we use MLM as a training objective where we mask only 15% of the tokens, so the \n",
    "training signal to the model is only those 15% of the tokens since it predicts only those masked tokens. But in ELECTRA, the training signal is\n",
    "all the tokens because here, the model classifies whether all the given tokens are original or replaced.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing \"INFO\" and \"WARNING\" messages by setting the verbosity of the Transformers library.\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizer, ElectraModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pretrained model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfff3008baab48c6a9a453285b9a83a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdca783f4c343e9a0549c299c8ca549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ElectraModel.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d521c81ad65340dba11f0016c51e79d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f61988e7ff84033be3008d30518f5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ElectraModel.from_pretrained('google/electra-small-generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraConfig {\n",
       "  \"_name_or_path\": \"google/electra-small-generator\",\n",
       "  \"architectures\": [\n",
       "    \"ElectraForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"embedding_size\": 128,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1024,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"electra\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"summary_activation\": \"gelu\",\n",
       "  \"summary_last_dropout\": 0.1,\n",
       "  \"summary_type\": \"first\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.30.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3e4d5fa6784e8088ccbe3aa220d3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca4f04836394e34be55f16e31776315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c8bc1919954641b5cdf3097a58a171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6122a74ad5143dc831c5fd439c7e086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"The dog is cute\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1996,  3899,  2003, 10140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = model(**inputs)\n",
    "hidden_rep = objects.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 256])\n",
      "tensor([-9.0066e-01,  1.6689e-01, -1.0052e+00, -2.0985e-01,  7.4740e-01,\n",
      "         4.8050e-01,  8.9076e-01,  6.2886e-01, -1.7570e-01, -1.2542e+00,\n",
      "        -1.5265e+00, -7.5520e-01,  4.2734e-01,  7.2674e-01,  1.0291e+00,\n",
      "         4.0141e-01,  9.0369e-01, -2.0499e-01, -2.0861e-01, -4.8087e-01,\n",
      "         6.7896e-01,  4.8444e-01,  1.0877e+00, -1.6838e-01,  2.2549e-01,\n",
      "         4.9599e-02,  1.6649e+00, -5.5879e-01, -1.2861e+00,  1.4240e+00,\n",
      "        -1.0735e+00, -2.0786e+00,  6.7480e-01,  1.6990e-01,  7.4186e-01,\n",
      "        -8.1543e-01, -7.6766e+00,  3.8491e-01, -6.7032e-01, -8.5981e-01,\n",
      "         7.3789e-01, -1.0038e-01,  2.8210e-01, -3.8917e-01, -1.0351e+00,\n",
      "         9.6054e-01,  1.1270e-01,  2.5980e-01,  9.8965e-02, -1.9503e+00,\n",
      "         4.4600e-01,  7.1412e-01,  6.2666e-01,  1.3863e-01, -5.6530e-03,\n",
      "         1.7137e+00, -4.0496e-01, -4.6221e-01,  8.0276e-01,  2.6045e-01,\n",
      "        -6.2693e-01, -8.1840e-01,  8.8280e-01, -1.2556e+00,  5.7909e-01,\n",
      "         7.8505e-01,  1.1504e-01, -9.1461e-01,  8.1849e-01, -1.1576e+00,\n",
      "        -3.2781e-01,  4.3701e-01, -8.8245e-01,  8.8172e-01,  3.9346e-01,\n",
      "         4.9359e-01,  2.0041e-01, -1.0573e-01, -5.7945e-02, -3.9864e-01,\n",
      "         9.9947e-01, -5.7582e-01,  7.0797e-01,  1.4114e+00,  1.0328e+00,\n",
      "         5.5955e-02, -1.7727e+00, -7.6224e-01, -5.2813e-03,  3.7345e-01,\n",
      "        -2.1092e+00, -7.5560e-03,  1.7763e-01,  6.5028e-01,  9.3564e-02,\n",
      "        -1.6747e-01, -6.0135e-02, -2.1364e-01, -1.9043e-01,  1.0763e+00,\n",
      "         1.5411e+00,  1.6763e+00, -1.5391e+00, -1.0755e+00, -3.8683e-02,\n",
      "        -1.0016e+00, -1.2269e+00, -6.0858e-01,  2.9846e-02, -3.1854e-01,\n",
      "        -6.0220e-01,  1.4673e-02, -1.7790e-01,  1.8766e-01,  1.2897e+00,\n",
      "         2.2941e+00, -9.6678e-01,  1.5380e+00,  1.6953e+00, -2.0810e+00,\n",
      "        -9.9164e-02,  6.5718e-02, -2.4549e-01, -3.4074e-01,  4.0576e-01,\n",
      "         1.2528e+00,  4.4231e-01,  1.6293e+00,  2.8081e-01,  1.5998e+00,\n",
      "         6.8212e-01, -2.9168e-01, -6.5975e-01,  1.0456e+00, -3.1016e-01,\n",
      "         1.0626e+00, -1.5832e-01, -3.3403e-01,  4.0934e-01,  1.6729e+00,\n",
      "        -1.3169e-01, -2.9804e+00, -9.7439e-01,  8.0661e-01,  1.3900e+00,\n",
      "        -5.8687e-03, -9.0172e-01,  9.0398e-01,  1.1246e+00, -6.3277e-01,\n",
      "        -7.7248e-01, -1.9833e-01, -1.3827e+00, -6.0373e-01, -1.4477e-01,\n",
      "        -8.6217e-02, -2.2812e-01,  8.5487e-01,  8.2031e-01,  1.7213e+00,\n",
      "         4.3737e-02,  1.8105e+00, -1.2354e-02, -2.1482e-01, -9.1814e-01,\n",
      "        -1.0635e-01,  1.0743e+00, -2.6714e-01, -6.9959e-01, -2.9887e-01,\n",
      "         1.0619e+00, -4.7515e-01, -3.3822e-01, -6.0923e-01,  8.1166e-01,\n",
      "         2.3820e-01,  1.7288e+00, -6.8600e-01, -6.2690e-01,  3.4448e-01,\n",
      "         3.3706e-01,  5.6797e-02,  1.1065e-01, -3.3470e-01,  2.5171e-01,\n",
      "        -1.3875e-01, -1.2030e-02, -9.6264e-01,  2.1596e+00, -9.9385e-02,\n",
      "        -2.0451e-02, -2.7164e-01, -1.3161e+00,  5.6704e-01, -1.3398e+00,\n",
      "        -3.7795e-01, -5.0531e-01,  1.4834e+00,  3.1165e-02, -7.2464e-02,\n",
      "         5.0199e-01,  2.0971e+00,  6.4033e-02, -3.6386e-01, -1.2369e+00,\n",
      "        -5.0860e-02, -7.8768e-01,  1.4322e+00, -4.7614e-01,  1.2213e-01,\n",
      "        -2.5800e-01, -6.0217e-02, -4.4275e-01, -2.7882e+01, -3.8839e-01,\n",
      "        -6.1931e-01, -8.4487e-03, -1.3707e+00, -1.1245e+00, -3.3108e-01,\n",
      "        -1.1724e+00,  1.2250e-01, -2.9942e-01,  8.1944e-01, -2.4210e-01,\n",
      "        -9.0237e-01,  1.4198e-01, -5.2677e-01,  3.2349e-01, -2.1265e-02,\n",
      "         2.5082e+00, -1.0708e+00, -2.5450e-01,  7.4487e-01,  7.1385e-01,\n",
      "         3.2597e-01,  1.0354e+00, -1.0515e-01, -2.5811e-01, -9.2833e-01,\n",
      "         8.5631e-01,  3.5494e-02, -1.5756e-01, -6.6473e-02,  3.1364e-01,\n",
      "        -7.6970e-01, -4.1241e-01,  8.3924e-01, -8.2974e-01, -2.2943e-01,\n",
      "        -2.7132e+00, -2.9193e-02,  2.2010e-01, -5.4746e-01,  2.9935e-01,\n",
      "        -2.1496e-01], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hidden_rep.shape)\n",
    "print(hidden_rep[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
